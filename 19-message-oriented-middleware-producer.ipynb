{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Kafka Producer for Twitter </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire and decompress Kafka**\n",
    "\n",
    "```\n",
    "$ wget http://download.nextag.com/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz\n",
    "$ tar xzf kafka_2.11-1.0.0.tgz\n",
    "```\n",
    "\n",
    "Run the following from separate terminals:\n",
    "\n",
    "```\n",
    "cd kafka_2.11-1.0.0\n",
    "bin/zookeeper-server-start.sh config/zookeeper.properties\n",
    "```\n",
    "\n",
    "```\n",
    "cd kafka_2.11-1.0.0\n",
    "bin/kafka-server-start.sh config/server.properties\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/software/kafka_2.11-1.0.0; \\\n",
    "    ./bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test\n",
    "!cd ~/software/kafka_2.11-1.0.0; \\\n",
    "    ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n",
    "!cd ~/software/kafka_2.11-1.0.0; \\\n",
    "    ./bin/kafka-topics.sh --list --zookeeper localhost:2181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete a topic:\n",
    "\n",
    "Add the following lines to `config/server.properties`: `delete.topic.enable=true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cd ~/software/kafka_2.11-1.0.0 & bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup Confluent_Kafka**\n",
    "\n",
    "First, install your own Anaconda to a local directory in your home on Palmetto. \n",
    "\n",
    "Next, perform the following steps\n",
    "\n",
    "```\n",
    "$ wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh\n",
    "$ sh Anaconda3-5.0.1-Linux-x86_64.sh\n",
    "$ export PATH=/home/lngo/software/anaconda3/bin:$PATH\n",
    "$ conda create --name kafka python=3.6\n",
    "$ source activate kafka\n",
    "$ conda install jupyter\n",
    "$ python -m ipykernel install --prefix=/home/lngo/.local/ --name 'Python-Kafka-3.6'\n",
    "$ conda install python-confluent-kafka\n",
    "$ conda install tweepy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "broker = 'localhost:9092'\n",
    "topic = 'test'\n",
    "\n",
    "# Producer configuration\n",
    "# See https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n",
    "conf = {'bootstrap.servers': broker}\n",
    "\n",
    "# Create Producer instance\n",
    "p = Producer(**conf)\n",
    "\n",
    "# Optional per-message delivery callback (triggered by poll() or flush())\n",
    "# when a message has been successfully delivered or permanently\n",
    "# failed delivery (after retries).\n",
    "def delivery_callback(err, msg):\n",
    "    if err:\n",
    "        sys.stderr.write('%% Message failed delivery: %s\\n' % err)\n",
    "    else:\n",
    "        sys.stderr.write('%% Message key %s delivered to %s [%d]\\n' % (msg.key(), msg.topic(), msg.partition()))\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            jsonData = json.loads(data)\n",
    "            p.produce(topic, json.dumps(data), key=str(jsonData['id']), callback=delivery_callback)\n",
    "        except BufferError as e:\n",
    "            sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))\n",
    "        p.poll(0)\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print (status)\n",
    "        \n",
    "# read cert (not on github)\n",
    "keyFile = open('/home/lngo/.cert/Twitter','r')\n",
    "CONSUMER_KEY = keyFile.readline().rstrip()\n",
    "CONSUMER_SECRET = keyFile.readline().rstrip()\n",
    "ACCESS_TOKEN_KEY = keyFile.readline().rstrip()\n",
    "ACCESS_TOKEN_SECRET = keyFile.readline().rstrip()\n",
    "\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        stream = Stream(auth, StdOutListener())\n",
    "        stream.filter(track=['Clemson'])\n",
    "    except IncompleteRead:\n",
    "        print (\"Lets try it again\")\n",
    "        continue\n",
    "    except KeyboardInterrupt:\n",
    "        stream.disconnect()\n",
    "        break\n",
    "        \n",
    "# Wait until all messages have been delivered\n",
    "sys.stderr.write('%% Waiting for %d deliveries\\n' % len(p))\n",
    "p.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Kafka-3.6",
   "language": "python",
   "name": "python-kafka-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
