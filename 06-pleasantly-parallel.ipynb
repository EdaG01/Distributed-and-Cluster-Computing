{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Pleasantly Parallel</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Embarrassingly parallel/naturally parallel/pleasantly parallel\n",
    "- “A computation that can obviously be divided into a number of completely different parts, each of which can be executed by a separate process.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- No communication or very little communication among the processes.\n",
    "- Each process can do its tasks without any interaction with the other processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Python's NumPy library**\n",
    "- Supports n-dimensional array\n",
    "- Provides optimized and vectorized operations on multi-dimensional arrays in large-scale computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**mpi4py and NumPy**\n",
    "- lower-case communitation routines (send, recv, gather, scatter, reduce) in mpi4py\n",
    "operate on Python's original data types with no optimization\n",
    "- upper-case communication routines (Send, Recv, Bcast, Scatter, Gather, Reduce ...) require\n",
    "Numpy and have syntax similar to the original MPI_xxxx routines in C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Upper-case point-to-point: MPI.Send**\n",
    "\n",
    "Comm.Send(buf, dest = 0, tag = 0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- buf (choice) – data to send\n",
    "- dest (integer) – rank of destination\n",
    "- tag (integer) – message tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Upper-case point-to-point: MPI.Recv**\n",
    "\n",
    "Comm.Recv(buf, source = 0, tag = 0, Status status = None)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- buf (choice) – initial address of receive buffer\n",
    "- source (integer) – rank of source\n",
    "- tag (integer) – message tag\n",
    "- status (Status) – status of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/sendrecvUpper.py\n",
    "#!/usr/bin/env python\n",
    "# sendrecvUpper.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); print(rank)\n",
    "a = numpy.zeros((4), dtype=numpy.int)\n",
    "status = MPI.Status()\n",
    "print (a)\n",
    "if rank == 0:\n",
    "    a = numpy.array([1,2,4])\n",
    "    print (a)\n",
    "    comm.Send(a, dest=1, tag = 1000)\n",
    "if rank == 1:\n",
    "    comm.Recv(a, source = 0, tag = MPI.ANY_TAG, status = status)\n",
    "    print (status.Get_source())\n",
    "    print (status.Get_tag())\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 2 codes/mpi4py/sendrecvUpper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Bcast**\n",
    "\n",
    "Comm.Bcast(buf, root=0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator across which to broadcast\n",
    "- buf (choice) – buffer\n",
    "- root (int) – rank of root operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/bcastUpper.py\n",
    "#!/usr/bin/env python\n",
    "# bcastUpper.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "rand_num = numpy.zeros(1)\n",
    "print (rand_num[0])\n",
    "if rank == 0:\n",
    "    rand_num[0] = numpy.random.uniform(0)\n",
    "    print(rand_num[0])\n",
    "comm.Bcast(rand_num, root = 0)\n",
    "print (\"Process\", rank, \"has the number\", rand_num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/bcastUpper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Scatter**\n",
    "\n",
    "Comm.Scatter(sendbuf, recvbuf, root)\n",
    "\n",
    "Parameters:\t\n",
    "- sendbuf (choice) – address of send buffer (significant only at root)\n",
    "- recvbuf (choice) – address of receive buffer\n",
    "- root (int) – rank of sending process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/scatterUpper.py\n",
    "#!/usr/bin/env python\n",
    "# scatterUpper.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank();size = comm.Get_size();LENGTH = 3\n",
    "if rank == 0:\n",
    "    x = numpy.linspace(1,size*LENGTH,size*LENGTH)\n",
    "    print (x)\n",
    "else:\n",
    "    x = None\n",
    "x_local = numpy.zeros(LENGTH)\n",
    "comm.Scatter(x, x_local, root=0)\n",
    "#you should notice that only the root process has a value for x that\n",
    "#is not \"None\"\n",
    "print (\"process\", rank, \"x:\", x)\n",
    "print (\"process\", rank, \"x_local:\", x_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/scatterUpper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Gather**\n",
    "\n",
    "Comm.Gather(sendbuf, recvbuf, root)\n",
    "\n",
    "Parameters:\t\n",
    "- sendbuf (choice) – address of send buffer (significant only at root)\n",
    "- recvbuf (choice) – address of receive buffer\n",
    "- root (int) – rank of receiving process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/gatherUpper.py\n",
    "#!/usr/bin/env python\n",
    "# gatherUpper.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "LENGTH = 3\n",
    "x = None\n",
    "x_local = numpy.linspace(rank*LENGTH,(rank+1)*LENGTH, LENGTH)\n",
    "print(x_local)\n",
    "if rank == 0:\n",
    "    x = numpy.zeros(size*LENGTH)\n",
    "    print (x)\n",
    "comm.Gather(x_local, x, root=0)\n",
    "\n",
    "#you should notice that only the root process has a value for x that\n",
    "#is not \"None\"\n",
    "print (\"process\", rank, \"x:\", x)\n",
    "print (\"process\", rank, \"x_local:\", x_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/gatherUpper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Reduce**\n",
    "\n",
    "Comm.Reduce(sendbuf, recvbuf, Op op = MPI.SUM, root = 0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- sendbuf (choice) – address of send buffer\n",
    "- recvbuf (choice) – address of receive buffer (only significant at root)\n",
    "- op (handle) – reduce operation\n",
    "- root (int) – rank of root operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- MPI.MAX:\tmaximum\n",
    "- MPI.MIN:\tminimum\n",
    "- MPI.SUM:\tsum\n",
    "- MPI.PROD:\tproduct\n",
    "- MPI.LAND:\tlogical and\n",
    "- MPI.BAND:\tbit-wise and\n",
    "- MPI.LOR:\tlogical or\n",
    "- MPI.BOR:\tbit-wise or\n",
    "- MPI.LXOR:\tlogical xor\n",
    "- MPI.BXOR:\tbit-wise xor\n",
    "- MPI.MAXLOC:\tmax value and location\n",
    "- MPI.MINLOC:\tmin value and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/reduceUpper.py\n",
    "#!/usr/bin/env python\n",
    "# reduceUpper.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "rankF = numpy.array(float(rank))\n",
    "total = numpy.zeros(1)\n",
    "comm.Reduce(rankF,total, op=MPI.MAX, root = 0)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/reduceUpper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# reducerUpper2.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "LENGTH = 3\n",
    "x = None\n",
    "x_local = numpy.linspace(rank*LENGTH,(rank+1)*LENGTH, LENGTH)\n",
    "print (x_local)\n",
    "total = numpy.zeros(LENGTH)\n",
    "comm.Reduce(x_local,total, op=MPI.SUM, root = 0)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/reduceUpper2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Example: Trapezoid Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/06/trapezoid01.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 8; a = 0; b = 2; h = (b - a)/N;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# With 4 processors (cores)\n",
    "size = 4; rank = 1\n",
    "local_N = N / size\n",
    "local_a = a + rank * h * local_N\n",
    "local_b = local_a + h * local_N\n",
    "print (local_a, local_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Which workload goes to which process?\n",
    "```\n",
    "if (rank == i) {\n",
    "\tdo great things\n",
    "}\n",
    "```\n",
    "- Start with small number of processes\n",
    "- Calculation workload assignment manually for each count of processes\n",
    "- Generalize assignment for process i based on sample calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/trapezoid1.py\n",
    "#!/usr/bin/env python\n",
    "# trapezoid1.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 1000; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size\n",
    "local_a = a + rank * local_N * h\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result += (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = local_a + h\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/trapezoid1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Does each process receive the same amount of work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/trapezoid2.py\n",
    "#!/usr/bin/env python\n",
    "# trapezoid2.py\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 8; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size\n",
    "local_a = a + rank * local_N * h\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result = partial_result + (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = local_a + h\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "print (\"Process \", rank, \" has \", partial_result[0])\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/trapezoid2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/06/static-wa.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/06/cyclic-wl.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/trapezoidCyclic.py\n",
    "#!/usr/bin/env python\n",
    "# trapezoidCyclic.py\n",
    "import numpy; from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 3000; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size; local_a = a + rank * h\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result = partial_result + (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = local_a + size * h\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "print (\"Process \", rank, \" has \", partial_result[0])\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/trapezoidCyclic.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/06/dynamic-wl.png\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile codes/mpi4py/trapezoidDynamic.py\n",
    "#!/usr/bin/env python\n",
    "# trapezoidDynamic.py\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "def f(x):\n",
    "    return x*x\n",
    "partial_result = numpy.zeros(1)\n",
    "local_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "h = numpy.zeros(1) \n",
    "a = numpy.zeros(1)\n",
    "status = MPI.Status()\n",
    "\n",
    "if (rank == 0):\n",
    "    N = 1000; a[0]= 0; b = 1; h[0]= (b - a)/N;\n",
    "    comm.Bcast(h, root = 0)\n",
    "    count = 0;\n",
    "    for i in range(1, size):\n",
    "        comm.Send(a,dest = i,tag = 1)\n",
    "        count = count + 1\n",
    "else:\n",
    "    comm.Bcast(h, root = 0)\n",
    "    comm.Recv(a,source = 0, tag = 1,status = status)\n",
    "\n",
    "if (rank != 0):\n",
    "    while True:\n",
    "        local_result[0] = h[0] * (f(a[0]) +  f(a[0] + h[0])) / 2\n",
    "        partial_result[0] += local_result[0];\n",
    "        comm.Send(local_result,dest = 0,tag = 1)      \n",
    "        comm.Recv(a, source = 0, tag = MPI.ANY_TAG, status = status)\n",
    "        if status.Get_tag() != 1:\n",
    "            break\n",
    "            \n",
    "if (rank == 0):\n",
    "    while (count < N):\n",
    "        comm.Recv(partial_result, source = MPI.ANY_SOURCE, tag = MPI.ANY_TAG, status = status)\n",
    "        sum[0] = sum[0] + partial_result[0]\n",
    "        local_a = numpy.array([a + count * h])\n",
    "        comm.Send(local_a, dest = status.Get_source(), tag = 1)\n",
    "        count = count + 1      \n",
    "    for i in range (1,size):\n",
    "        comm.Recv(partial_result, source = MPI.ANY_SOURCE, tag = MPI.ANY_TAG, status = status)\n",
    "        sum = sum + partial_result\n",
    "    for i in range (1,size):\n",
    "        comm.Send(a,dest = i,tag = 0)\n",
    "    print (\"The integral is %s\" % (sum))\n",
    "else:\n",
    "    print (\"The partial_integral is %s\" % (partial_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 codes/mpi4py/trapezoidDynamic.py"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
